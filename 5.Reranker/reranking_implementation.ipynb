{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a06d838-8771-444f-a21e-dade873bcb31",
   "metadata": {},
   "source": [
    "# Install/ import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb2b86-cf1d-48bd-b2c9-1088329661be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "684d2f60-956f-4afb-a08a-9660ff658b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yiehy\\OneDrive\\Desktop\\cs425-nlc-project\\5.Reranker\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f091e0-590a-4e5d-8582-d987e6b29cbc",
   "metadata": {},
   "source": [
    "# Best performing bi-encoder (retrieve and re-rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e875928-c058-4367-8899-f6cfb695e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_encoder_model = SentenceTransformer(\"../8.Fine-tuned Models/finetuned-bertbase-1epoch\")\n",
    "cross_encoder_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695d34f-d93d-48b8-914c-12c4b14b71e8",
   "metadata": {},
   "source": [
    "# On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab07cb46-e58b-400d-aada-1ee91dcc5c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read embeddings\n",
    "test_answer_embeddings = pickle.load(open(\"../4.Retrieval/finetuned_bertbase/finetuned_bertbase_test_answer_embeddings.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef54bd4e-8110-4b42-81e9-1cbda5e74d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../0.Datasets/train_test_split/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da2ffbfd-07f8-46b3-a47e-2f12132e7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_index_map = {}\n",
    "for _,row in test_df.iterrows():\n",
    "    if row[\"qid\"] not in question_answer_index_map:\n",
    "        question_answer_index_map[row[\"qid\"]]= []\n",
    "        question_answer_index_map[row[\"qid\"]].append(row[\"docid\"])\n",
    "    else:\n",
    "        question_answer_index_map[row[\"qid\"]].append(row[\"docid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "777ed537-180c-4e73-8eab-853ad3f77b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for v in question_answer_index_map.values():\n",
    "    labels.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f7f4632-5d2e-46ae-9f90-5146a71ad093",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_map = {}\n",
    "label_map = {}\n",
    "for _,row in test_df.iterrows():\n",
    "    if row[\"qid\"] not in question_map:\n",
    "        question_map[row[\"qid\"]] = row[\"question\"]\n",
    "    if row[\"answer\"] not in label_map:\n",
    "        label_map[row[\"answer\"]] = row[\"docid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3da989fd-ff4f-4c42-b442-7e2995a91df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "test_answer_list = test_df[\"answer\"].tolist()\n",
    "predictions = []\n",
    "count=1\n",
    "for k,v in question_map.items():\n",
    "    if count%100==0:\n",
    "        print(count)\n",
    "    question_embedding = bi_encoder_model.encode(v)\n",
    "    answer_similiarity = {}\n",
    "    for i,embed in enumerate(test_answer_embeddings):\n",
    "        answer_similiarity[i]= np.dot(question_embedding, embed)\n",
    "    answer_similiarity = {k: v for k, v in sorted(answer_similiarity.items(), key=lambda item: item[1], reverse=True)}\n",
    "    top_20_hits = []\n",
    "    for item in list(answer_similiarity)[:20]:\n",
    "        top_20_hits.append(test_answer_list[item])\n",
    "    cross_encoder_answer_similiarity = {}\n",
    "    for hit in top_20_hits:\n",
    "        cross_encoder_answer_similiarity[hit] = cross_encoder_model.predict([v,hit])\n",
    "    cross_encoder_answer_similiarity = {k: v for k, v in sorted(cross_encoder_answer_similiarity.items(), key=lambda item: item[1], reverse=True)}\n",
    "    label_index = label_map[list(cross_encoder_answer_similiarity.keys())[0]]\n",
    "    predictions.append([label_index])\n",
    "    count+=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1311a576-38a6-4ae9-9f05-d855cdcd1638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save prediction and results\n",
    "results = {\"labels\":labels,\"predictions\":predictions}\n",
    "with open(\"../7.Evaluate/cross_encoder.pkl\", 'wb') as f:\n",
    "    pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1aeb4b-7959-4f64-aeb0-59cf619c994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ninja/opt/anaconda3/lib/python3.7/site-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "qna_df = pd.read_csv(\"./data/QnA.csv\")\n",
    "\n",
    "import pickle\n",
    "sentence_embeddings = pickle.load(open(\"./embeddings.pkl\", 'rb'))\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "bi_encoder_model = SentenceTransformer(\"./finetuned-bertbase-1epoch\")\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "cross_encoder_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    "\n",
    "def predict(user_message):\n",
    "    # bi encoder - retriever\n",
    "    question_embedding = bi_encoder_model.encode(user_message)\n",
    "    answer_similiarity = {}\n",
    "    for i,embed in enumerate(sentence_embeddings):\n",
    "        answer_similiarity[i]= np.dot(question_embedding, embed)\n",
    "    answer_similiarity = {k: v for k, v in sorted(answer_similiarity.items(), key=lambda item: item[1], reverse=True)}\n",
    "    top_20_hits = []\n",
    "    for item in list(answer_similiarity)[:20]:\n",
    "        top_20_hits.append(qna_df['answer'].to_list()[item])\n",
    "    \n",
    "    # cross encoder - reranker\n",
    "    cross_encoder_answer_similarity = {}\n",
    "    for hit in top_20_hits:\n",
    "        cross_encoder_answer_similarity[hit] = cross_encoder_model.predict([user_message,hit])\n",
    "    cross_encoder_answer_similarity = {k: v for k, v in sorted(cross_encoder_answer_similarity.items(), key=lambda item: item[1], reverse=True)}\n",
    "    print(cross_encoder_answer_similarity)\n",
    "    answer = list(cross_encoder_answer_similarity.keys())[0]\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e45c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If your financial needs aren\\'t complex, and mostly limited to portfolio management, consider looking into the newish thing called robo-advisers (proper term is \"Automated investing services\").  The difference is that robo-advisers use software to manage portfolios on a large scale, generating big economy of scale and therefore offering a much cheaper services than personal advisor would - and unless your financial needs are extremely complex, the state of the art of scaled up portfolio management is at the point that a human advisor really doesn\\'t give you any value-add (and - as other answers noted - human advisor can easily bring in downsides such as conflict of interest and lack of fiduciary responsibility).  disclaimer: I indirectly derive my living from a company which derives a very small part of their income from a robo-adviser, therefore there\\'s a possible small conflict of interest in my answer'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_message = \"\"\"\n",
    "should we have a financial advisor or a robo advisor\n",
    "\"\"\"\n",
    "predict(user_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdbc871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
