{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "889c9234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#!pip install sentence-transformers\n",
    "# !pip install spacy-wordnet\n",
    "# !pip install -U spacy --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c1d497-a75b-4283-96a8-ac73b498f0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.0\n",
      "C:\\Users\\yiehy\\OneDrive\\Desktop\\cs425-nlc-project\\6.Query Expansion\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import re\n",
    "!python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator \n",
    "print(spacy.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c2c053-2093-43da-85d9-903b7ff496b4",
   "metadata": {},
   "source": [
    "# Best performing flow (retrieve and re-rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2f34dc-5cbe-4505-b72f-2c902d15d3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yiehy\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bi_encoder_model = SentenceTransformer(\"../8.Fine-tuned Models/finetuned-bertbase-1epoch\")\n",
    "cross_encoder_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f8af1-cb22-4c54-add4-3deb4ca08ff2",
   "metadata": {},
   "source": [
    "# On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90ea7b32-678f-4a12-a9a4-88f76736c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### UNCOMMENT AND RUN THE CODE BELOW IF YOU FACE THE ERROR \"UNSUPPORTED PICKLE PROTOCOL: 5\" WHEN RUNNING THIS CELL #####\n",
    "# #!pip3 install pickle5\n",
    "# import pickle5 as pickle\n",
    "##########################################################################################################################\n",
    "\n",
    "# Read embeddings\n",
    "test_answer_embeddings = pickle.load(open(\"../4.Retrieval/finetuned_bertbase/finetuned_bertbase_test_answer_embeddings.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece7b91b-a862-4a96-86fe-2b71eda49f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13786</td>\n",
       "      <td>7817</td>\n",
       "      <td>31330</td>\n",
       "      <td>Can you have a positive return with a balance ...</td>\n",
       "      <td>Have you owned the stock for longer than 2015?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11485</td>\n",
       "      <td>6304</td>\n",
       "      <td>105557</td>\n",
       "      <td>Oversimplify it for me: the correct order of i...</td>\n",
       "      <td>Great questions -- the fact that you're thinki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12711</td>\n",
       "      <td>7115</td>\n",
       "      <td>43508</td>\n",
       "      <td>Definition of “U.S. source” for US non-residen...</td>\n",
       "      <td>The examples you provide in the question are c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10336</td>\n",
       "      <td>5716</td>\n",
       "      <td>287327</td>\n",
       "      <td>Are car buying services worth it?</td>\n",
       "      <td>I have used car buying services through Costco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15084</td>\n",
       "      <td>9016</td>\n",
       "      <td>580920</td>\n",
       "      <td>What makes a Company's Stock prices go up or d...</td>\n",
       "      <td>Here are some significant factors affect the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>6117</td>\n",
       "      <td>3567</td>\n",
       "      <td>579472</td>\n",
       "      <td>Will getting a new credit card and closing ano...</td>\n",
       "      <td>Several events will always result in a reducti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3411</th>\n",
       "      <td>8218</td>\n",
       "      <td>4446</td>\n",
       "      <td>82194</td>\n",
       "      <td>Why are “random” deposits bad?</td>\n",
       "      <td>Random deposits are a bit like playing the lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>6545</td>\n",
       "      <td>3733</td>\n",
       "      <td>99619</td>\n",
       "      <td>Rental Application Fees</td>\n",
       "      <td>Slightly abbreviated version of the guidance f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>1585</td>\n",
       "      <td>1417</td>\n",
       "      <td>303501</td>\n",
       "      <td>Market Cap lower than Shares Outstanding x Sha...</td>\n",
       "      <td>The definition of market cap is exactly shares...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>9115</td>\n",
       "      <td>4962</td>\n",
       "      <td>599925</td>\n",
       "      <td>Net Cash Flows from Selling the Bond and Inves...</td>\n",
       "      <td>Investopedia has a good explanation of the ter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3415 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   qid   docid  \\\n",
       "0          13786  7817   31330   \n",
       "1          11485  6304  105557   \n",
       "2          12711  7115   43508   \n",
       "3          10336  5716  287327   \n",
       "4          15084  9016  580920   \n",
       "...          ...   ...     ...   \n",
       "3410        6117  3567  579472   \n",
       "3411        8218  4446   82194   \n",
       "3412        6545  3733   99619   \n",
       "3413        1585  1417  303501   \n",
       "3414        9115  4962  599925   \n",
       "\n",
       "                                               question  \\\n",
       "0     Can you have a positive return with a balance ...   \n",
       "1     Oversimplify it for me: the correct order of i...   \n",
       "2     Definition of “U.S. source” for US non-residen...   \n",
       "3                     Are car buying services worth it?   \n",
       "4     What makes a Company's Stock prices go up or d...   \n",
       "...                                                 ...   \n",
       "3410  Will getting a new credit card and closing ano...   \n",
       "3411                     Why are “random” deposits bad?   \n",
       "3412                            Rental Application Fees   \n",
       "3413  Market Cap lower than Shares Outstanding x Sha...   \n",
       "3414  Net Cash Flows from Selling the Bond and Inves...   \n",
       "\n",
       "                                                 answer  \n",
       "0     Have you owned the stock for longer than 2015?...  \n",
       "1     Great questions -- the fact that you're thinki...  \n",
       "2     The examples you provide in the question are c...  \n",
       "3     I have used car buying services through Costco...  \n",
       "4     Here are some significant factors affect the c...  \n",
       "...                                                 ...  \n",
       "3410  Several events will always result in a reducti...  \n",
       "3411  Random deposits are a bit like playing the lot...  \n",
       "3412  Slightly abbreviated version of the guidance f...  \n",
       "3413  The definition of market cap is exactly shares...  \n",
       "3414  Investopedia has a good explanation of the ter...  \n",
       "\n",
       "[3415 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../0.Datasets/train_test_split/test.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74876466-f0d6-4661-9768-a0b780523321",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_index_map = {}\n",
    "for _,row in test_df.iterrows():\n",
    "    if row[\"qid\"] not in question_answer_index_map:\n",
    "        question_answer_index_map[row[\"qid\"]]= []\n",
    "        question_answer_index_map[row[\"qid\"]].append(row[\"docid\"])\n",
    "    else:\n",
    "        question_answer_index_map[row[\"qid\"]].append(row[\"docid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8866eb4-2e4b-4f51-9ef8-9a79edda0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [] # 2d list, with each value in the list being a list of docids that answer the same qid\n",
    "for v in question_answer_index_map.values():\n",
    "    labels.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140b0a02-e783-4197-9c71-ffe931556f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_map = {} # mapping of qid to question text\n",
    "label_map = {} # mapping of docid to answer text\n",
    "for _,row in test_df.iterrows():\n",
    "    if row[\"qid\"] not in question_map:\n",
    "        question_map[row[\"qid\"]] = row[\"question\"]\n",
    "    if row[\"answer\"] not in label_map:\n",
    "        label_map[row[\"answer\"]] = row[\"docid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11d3d219-78ca-4416-ac07-1c300b808475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performs basic data cleaning on query: standardize capitalization to lower, remove punctuations, remove redundant whitespaces\n",
    "def basic_cleaning(query):\n",
    "    query = str(query)\n",
    "    query = query.lower()\n",
    "    query = re.sub(r'[^\\w\\s]','',query)\n",
    "    query = ' '.join(query.split())\n",
    "    return query\n",
    "\n",
    "# Extract nouns\n",
    "def nouns_only(query):\n",
    "    try:\n",
    "        tagged_text = nltk.tag.pos_tag(query.split())\n",
    "        nouns_list = [word for word,tag in tagged_text if  tag == 'NNP' or tag == 'NNPS' or tag==\"NN\" or tag==\"NNS\"]\n",
    "        return list(set(nouns_list))\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "def query_noun_mapping(query_nouns):\n",
    "    synonym_dict = {}\n",
    "    for query_noun in query_nouns:\n",
    "        try:\n",
    "            closest_noun = wn.synsets(query_noun)[0].lemmas()[1].name()\n",
    "            synonym_dict[query_noun] = closest_noun\n",
    "        except:\n",
    "            pass\n",
    "    return synonym_dict\n",
    "\n",
    "def query_expansion(query):\n",
    "    try:\n",
    "        clean_query = basic_cleaning(query)\n",
    "        query_nouns_list = nouns_only(clean_query)\n",
    "        if len(query_nouns_list)==0:\n",
    "            return query\n",
    "        else:\n",
    "            synonym_dict = query_noun_mapping(query_nouns_list)\n",
    "        if len(synonym_dict.keys()) == 0:\n",
    "            return query\n",
    "        else:\n",
    "            for k,v in synonym_dict.items():\n",
    "                new_string = f\"{k} and {v}\"\n",
    "                query = query.replace(k,new_string)\n",
    "        return query\n",
    "    except:\n",
    "        return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e6f1894-50ea-4da4-8170-78e5cc099f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_answer_list = test_df[\"answer\"].tolist()\n",
    "predictions = []\n",
    "count = 1\n",
    "for k,v in question_map.items():\n",
    "    if count%100==0:\n",
    "        print(count)\n",
    "    try:\n",
    "        v = query_expansion(v)\n",
    "    except:\n",
    "        pass\n",
    "    question_embedding = bi_encoder_model.encode(v)\n",
    "    answer_similiarity = {}\n",
    "    for i,embed in enumerate(test_answer_embeddings):\n",
    "        answer_similiarity[i] = np.dot(question_embedding,embed)\n",
    "    answer_similiarity = {k: v for k, v in sorted(answer_similiarity.items(), key=lambda item: item[1], reverse=True)}\n",
    "    top_20_hits = []\n",
    "    for item in list(answer_similiarity)[:20]:\n",
    "        top_20_hits.append(test_answer_list[item])\n",
    "    cross_encoder_answer_similiarity = {}\n",
    "    for hit in top_20_hits:\n",
    "        cross_encoder_answer_similiarity[hit] = cross_encoder_model.predict([v,hit])\n",
    "    cross_encoder_answer_similiarity = {k: v for k, v in sorted(cross_encoder_answer_similiarity.items(), key=lambda item: item[1], reverse=True)}\n",
    "    label_index = label_map[list(cross_encoder_answer_similiarity.keys())[0]]\n",
    "    predictions.append([label_index])\n",
    "    count+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813b798-0f97-4b16-a4f7-6e15c16d781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save prediction and results\n",
    "results = {\"labels\":labels,\"predictions\":predictions}\n",
    "with open(\"../7.Evaluate/query_expansion.pkl\", 'wb') as f:\n",
    "    pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7d089",
   "metadata": {},
   "source": [
    "# New Domain-Based Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2988f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an spacy model (supported models are \"es\", \"en\" and \"pt\") \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Spacy 3.x\n",
    "nlp.add_pipe(\"spacy_wordnet\", after='tagger', config={'lang': nlp.lang})\n",
    "# Spacy 2.x\n",
    "# self.nlp_en.add_pipe(WordnetAnnotator(self.nlp_en.lang))\n",
    "token = nlp('prices')[0]\n",
    "\n",
    "# wordnet object link spacy token with nltk wordnet interface by giving acces to\n",
    "# synsets and lemmas \n",
    "token._.wordnet.synsets()\n",
    "token._.wordnet.lemmas()\n",
    "\n",
    "# And automatically tags with wordnet domains\n",
    "token._.wordnet.wordnet_domains()\n",
    "\n",
    "def get_similar_words(current_token, synonyms_list, number_of_domain_lemma=3):\n",
    "    result = []\n",
    "    if number_of_domain_lemma > len(synonyms_list):\n",
    "        return synonyms_list\n",
    "    for i in range(number_of_domain_lemma):\n",
    "        synonym = synonyms_list[i]\n",
    "        result.append(synonym)\n",
    "\n",
    "    if current_token not in result:\n",
    "        result[number_of_domain_lemma-1] = current_token\n",
    "\n",
    "    return result\n",
    "\n",
    "def query_expansion_v2(query, domains=['insurance', 'banking', 'finance', 'money'], number_of_domain_lemma=3):\n",
    "\n",
    "    \"\"\"\n",
    "    @params:\n",
    "        query: the question to be query-expanded\n",
    "        domains: the specific domains to get the synonyms from, eg. some possible_domains are ['finance', 'banking', 'insurance', 'money', 'economy']\n",
    "        number_of_domain_lemma: the number of synonyms you want, including the original word\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    enriched_sentence = []\n",
    "    sentence = nlp(query)\n",
    "\n",
    "    # For each token in the sentence\n",
    "    for token in sentence:\n",
    "        # print(token.text, token.pos_)\n",
    "        # We get those synsets within the desired domains\n",
    "        synsets = token._.wordnet.wordnet_synsets_for_domain(domains)\n",
    "        \n",
    "        \n",
    "        if not synsets: \n",
    "            enriched_sentence.append(token.text)\n",
    "        else:\n",
    "            # If we found a synset in the economy domains and the word is a noun\n",
    "            # we get the variants and add them to the enriched sentence\n",
    "            if token.pos_ == 'NOUN' or token.pos_ == 'VERB':\n",
    "                # lemmas_for_synset = [lemma for s in synsets for lemma in s.lemma_names()] # 2d list comprehension\n",
    "                lemmas_for_synset = []\n",
    "                for s in synsets:\n",
    "                    # print(s.lemma_names())\n",
    "                    for lemma in s.lemma_names():\n",
    "                        # print(lemma)\n",
    "                        lemmas_for_synset.append(lemma)\n",
    "\n",
    "                \n",
    "                synonyms = get_similar_words(token.text, lemmas_for_synset, number_of_domain_lemma)\n",
    "                synonyms = list(dict.fromkeys(synonyms))\n",
    "                enriched_sentence.append('{}'.format(' and '.join(synonyms)))\n",
    "            else:\n",
    "                enriched_sentence.append(token.text)\n",
    "        # try:\n",
    "        #     print(token, lemmas_for_synset)\n",
    "        #     lemmas_for_synset = []\n",
    "        # except:\n",
    "        #     pass\n",
    "\n",
    "    enriched_sentence = \" \".join(enriched_sentence)\n",
    "    enriched_sentence = enriched_sentence.replace(\"_\",\" \")\n",
    "    return enriched_sentence\n",
    "    # eg. I (need|want|require) to (draw|withdraw|draw_off|take_out) 5,000 euros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79d75896-d53f-418c-8de4-006ff6e212bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "# Get predictions with new query expansion code\n",
    "\n",
    "test_answer_list = test_df[\"answer\"].tolist()\n",
    "updated_predictions = []\n",
    "count = 1\n",
    "for k,v in question_map.items():\n",
    "    if count%100==0:\n",
    "        print(count)\n",
    "    try:\n",
    "        v = query_expansion_v2(v)\n",
    "    except:\n",
    "        pass\n",
    "    question_embedding = bi_encoder_model.encode(v)\n",
    "    answer_similiarity = {}\n",
    "    for i,embed in enumerate(test_answer_embeddings):\n",
    "        answer_similiarity[i] = np.dot(question_embedding,embed)\n",
    "    answer_similiarity = {k: v for k, v in sorted(answer_similiarity.items(), key=lambda item: item[1], reverse=True)}\n",
    "    top_20_hits = []\n",
    "    for item in list(answer_similiarity)[:20]:\n",
    "        top_20_hits.append(test_answer_list[item])\n",
    "    cross_encoder_answer_similiarity = {}\n",
    "    for hit in top_20_hits:\n",
    "        cross_encoder_answer_similiarity[hit] = cross_encoder_model.predict([v,hit])\n",
    "    cross_encoder_answer_similiarity = {k: v for k, v in sorted(cross_encoder_answer_similiarity.items(), key=lambda item: item[1], reverse=True)}\n",
    "    label_index = label_map[list(cross_encoder_answer_similiarity.keys())[0]]\n",
    "    updated_predictions.append([label_index])\n",
    "    count+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d95c9a0-84b5-49b4-acc5-bf4b9f51fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save prediction and results\n",
    "results = {\"labels\":labels,\"predictions\":updated_predictions}\n",
    "with open(\"../7.Evaluate/updated_query_expansion.pkl\", 'wb') as f:\n",
    "    pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0acc50-7ff5-4a6c-94f3-3e9d76a83d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab8062-5923-4342-8ada-78212e35ddcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7916278c-763a-4a41-8813-a93c6aeb02a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae67c46-1447-4a0e-8a0f-69c13596465a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbfbfc7-b630-4b70-97bc-27c1c0a1d11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53170300-d665-4a2e-9e9e-e07ca2a672ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506553d-4a01-47ea-ba4a-daa6b967ad43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aa6484-57e5-4fbf-8404-5f8dad7b6618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c74c3-a9c7-4fd4-a01e-cc79252a0d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f88a34-0455-4bb4-a19d-6bae4bf2f2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f1b465-bbd7-4d3a-8200-554b18bbe455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa80d4-87b9-4e01-b684-001e09027274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5369bf-692c-4817-b9cf-93494f1dfd45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1647c9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Can you have a positive return with a balance below cost basis?\n",
      "\n",
      "Query Expansion Result: Can you rich_person and wealthy_person and have a positive tax_return and income_tax_return and return with a balance below cost and monetary_value and price basis ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_query = list(question_map.values())[0]\n",
    "#test_query = question_map[7817]\n",
    "test_domain=['insurance', 'banking', 'finance', 'money']\n",
    "print(\"Original:\", test_query)\n",
    "print()\n",
    "print(\"Query Expansion Result:\", query_expansion_v2(test_query, domains=test_domain))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cec0c7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Can you have a positive return with a balance below cost basis?\n",
      "Query Expansion Result: Can you rich_person and wealthy_person and have a positive tax_return and income_tax_return and return with a balance below cost and monetary_value and price basis ?\n",
      "\n",
      "Original: Oversimplify it for me: the correct order of investing\n",
      "Query Expansion Result: Oversimplify it for me : the correct order and purchase_order and regulate of investing and investment and invest\n",
      "\n",
      "Original: Definition of “U.S. source” for US non-resident alien capital gains tax\n",
      "Query Expansion Result: Definition of “ U.S. beginning and origin and source ” for US non - resident alien capital and working_capital addition and increase and gains tax and taxation and revenue_enhancement\n",
      "\n",
      "Original: Are car buying services worth it?\n",
      "Query Expansion Result: Are car and auto and automobile buy and purchase services and service worth it ?\n",
      "\n",
      "Original: What makes a Company's Stock prices go up or down?\n",
      "Query Expansion Result: What make and do and makes a Company 's Stock monetary_value and price and prices travel and go and move up or down ?\n",
      "\n",
      "Original: Tax deductions on empty property\n",
      "Query Expansion Result: tax and taxation and Tax tax_write-off and tax_deduction and deductions on empty property and belongings and holding\n",
      "\n",
      "Original: I am the sole owner of an LLC. Does it make a difference if I file as an S-Corp or a sole-member LLC?\n",
      "Query Expansion Result: I am the sole owner and proprietor of an LLC . Does it make and do a deviation and divergence and difference if I file and register as an S - Corp or a sole - member LLC ?\n",
      "\n",
      "Original: Buy home and leverage roommates, or split rent?\n",
      "Query Expansion Result: buy and purchase home and leverage roommates , or split and stock_split and split_up rent and economic_rent ?\n",
      "\n",
      "Original: Do stock option prices predicate the underlying stock's movement?\n",
      "Query Expansion Result: Do stock and store option monetary_value and price and prices predicate the underlying stock and store 's motion and movement and move ?\n",
      "\n",
      "Original: Possible pro-rated division of asset strategies without a prenup?\n",
      "Query Expansion Result: Possible pro - rated division of asset and plus strategies without a prenup ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    test_query = list(question_map.values())[i]\n",
    "    #test_query = question_map[7817]\n",
    "    test_domain=['insurance', 'banking', 'finance', 'money']\n",
    "    print(\"Original:\", test_query)\n",
    "    print(\"Query Expansion Result:\", query_expansion_v2(test_query, domains=test_domain,number_of_domain_lemma=3))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c343b144-226e-4334-9d22-5620536d849e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
